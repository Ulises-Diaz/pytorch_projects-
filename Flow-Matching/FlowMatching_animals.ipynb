{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook you will learn how to implement a Flow Matching Algorithm to create Animals, Note that you could change the Dataset and create different objects.\n",
        "\n",
        "This is aswell Part of the project presented at ICRA 2026, made by @eduardoHernandez and @UlisesDiaz.\n",
        "\n",
        "Each section will have a Mathematical Explation, the goal is to make it easier to understand. Thus, it will have several animations to make you understand\n",
        "\n",
        "Note that this is animations and the mathematical explanation is not on the official Code.\n",
        "\n",
        "We make this to help the community into this topic.\n",
        "\n",
        "It is important to note that most of it, comes from : where, they explain each detail, so go and see it.\n",
        "\n",
        "\n",
        "Hope you like it.\n"
      ],
      "metadata": {
        "id": "WYQNgdd1NhTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Dependencies\n",
        "\n",
        "1.- Torch, torchvision, torchaudio,\n",
        "2.- matplotlib , numpy, tqdm, pillow\n",
        "3.- gdown\n",
        "4.- einops"
      ],
      "metadata": {
        "id": "FUfAKxQuOc6X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNIzUOybIoL9"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install matplotlib numpy tqdm pillow\n",
        "!pip install gdown # for dataset download\n",
        "!pip install einops  #for tensor manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Initial Configuration\n",
        "\n",
        "Standard Pytorch configurations\n"
      ],
      "metadata": {
        "id": "aVzOMpC2QI2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch configurations\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "\n",
        "# python imports\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple, Optional\n",
        "import math\n",
        "import einops\n",
        "\n",
        "# Configurar dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Seeds for reproducibility\n",
        "'''\n",
        "These are used to reproduce the experiment we have\n",
        "'''\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2r9VXfsQNUM",
        "outputId": "d1a26607-daad-4ec5-d08c-d1bd66e307f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Download and Prepare Dataset\n",
        "\n",
        "Note that you can change for any dataset you want, the code should work the same\n",
        "\n",
        "Download the dataset in: https://www.dropbox.com/scl/fi/kpxh6hu04eu28yb8l30wy/afhq.zip?e=2&rlkey=usjnva71u164xd4rq6ghlab1u&dl=0\n"
      ],
      "metadata": {
        "id": "zhTwtpDWR0Fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Using the Dataset\n",
        "\n",
        "Here,  we sample and get the transforms of the Dataset Above"
      ],
      "metadata": {
        "id": "XweHdRQ-VvS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we need to pass from image to tensor\n",
        "\n",
        "def get_transform(image_size = 64):\n",
        "  return transforms.Compose(\n",
        "      [\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transform.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) #[R, G, B]\n",
        "      ]\n",
        "  )\n",
        "\n",
        "\n",
        "# Create personalized Dataset\n",
        "\n",
        "class AnimalDataset(Dataset) :\n",
        "  def __init__(self, root_dir, transform = None) :\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transforms\n",
        "\n",
        "    # Create list of images\n",
        "    self.images = []\n",
        "\n",
        "    # Search for any type of image\n",
        "\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "      for file in files:\n",
        "          if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "              self.images.append(os.path.join(root, file))\n",
        "\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__ (self, idx) :\n",
        "    img_path = self.images[idx]\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    if self.transform :\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 64\n",
        "BATHC_SIZE = 32\n",
        "\n",
        "transforms = get_transform(IMAGE_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "tran_dataset = AnimalDataset('data/afhq/train', transform = transforms)\n",
        "\n",
        " # n_workers = how the data is process during training. Is like using a GPU, we have 4 workers loading data, applying transformations, and preparing batches\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATHC_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "print(f\"Dataset cargado: {len(train_dataset)} im√°genes\")\n",
        "print(f\"Dimensiones de imagen: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
        "\n",
        "\n",
        "def show_samples (loader, num_samples = 8) :\n",
        "  batch = next(iter(loader))\n",
        "  images = batch[:num_samples]\n",
        "\n",
        "  images = (images + 1 )/2\n",
        "\n",
        "  grid = make_grid (images, nrow = 4, padding= 2)\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.imshow(grid.permute(1,2,0))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "show_samples(train_loader)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8B3cT_QSTe4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "86701a2f-27e6-4fbb-c3bd-f006734fcbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3740541263.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Create personalized Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAnimalDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Initial Gaussian Distribution\n",
        "\n",
        "Here we start seeing actual stuff on Flow Matching.\n",
        "\n",
        "Fist, we need a classs to manage the sampling of Gaussian Distribution x0 , we start from pure noise (Gaussian Distribution) to real data (images)\n",
        "\n",
        "\n",
        "To see the explanation of Flow Matching and the Notes of the paper, see `section 0`\n",
        "\n",
        "The explanation of this Part is in Lecture 1. Go and see it.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7PTKL2X0dFvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "zUNOD_LvTey_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}