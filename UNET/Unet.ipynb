{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPooPR6V3s0dg03fi8vgeoo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"EWOyuYIwqh_K","executionInfo":{"status":"ok","timestamp":1746941286042,"user_tz":360,"elapsed":10,"user":{"displayName":"Alan Ulises Díaz Arenas","userId":"02926404634191896650"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms.functional as TF\n"]},{"cell_type":"code","source":["class DoubleConv(nn.Module):\n","  def __init__(self, in_channels, out_channels):\n","    super(DoubleConv, self).__init__()\n","    self.conv = nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False), #kernelsize, stride, padding (input,height,width will be the same in the output)\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False), #kernelsize, stride, padding (input,height,width will be the same in the output)\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(inplace=True),\n","        )\n","\n","  def forward(self, x) :\n","    return self.conv(x)\n","\n","class UNET (nn.Module):\n","  def __init__(self, in_channels = 3, out_channels = 1, features = [64, 128, 256, 512],): #for binary segmentation we use 1 in out_channels. If we want to segmentate more, we change this numbe\n","    super(UNET, self).__init__()\n","    self.ups = nn.ModuleList() # To store Conv Layers\n","    self.downs = nn.ModuleList()\n","    self.pool = nn.MaxPool2d(kernel_size=2 , stride = 2)\n","    # important to choose input divisible by 16 to be able to concatenate them\n","\n","    # Down Part UNET\n","    for feature in features :\n","      self.downs.append(DoubleConv(in_channels, feature))\n","      in_channels = feature\n","\n","    # Up part UNET\n","    for feature in reversed(features) :\n","      self.ups.append(\n","          nn.ConvTranspose2d(\n","              feature*2, feature, kernel_size= 2, stride = 2  #feature*2 is the connection path. We concatenate Decoder and encoder, kernel_size and stride will double hight and width\n","          )\n","      )\n","      self.ups.append(DoubleConv(feature*2, feature)) #because it has 3 conv layers each stage. It \"ups\" and then 2 convs\n","\n","    # Bottleneck\n","    self.bottleneck = DoubleConv(features[-1], features[-1]*2) # EXPLAIN\n","\n","    # Final conv to change # channels\n","    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size = 1)\n","\n","  def forward(self, x):\n","    connecting_paths = [] #explain x2\n","    for down in self.downs :\n","      x = down(x)\n","      connecting_paths.append(x)\n","      x = self.pool(x) # Decreasess the resolution (downsamples images) as it goes downwards\n","\n","    # Bottleneck\n","    x = self.bottleneck(x)\n","    connecting_paths = connecting_paths[::-1] # reverse list to upsample\n","\n","    for idx in range(0, len(self.ups), 2) : # up and double conv (single step)\n","      x = self.ups[idx](x)\n","      connecting_path = connecting_paths[idx//2] # explain x3\n","\n","      if x.shape != connecting_path.shape : # in the paper they cropped it\n","        x = TF.resize(x, size = connecting_path.shape[2:]) # we resize it.\n","\n","      cat_path = torch.cat((connecting_path, x), dim = 1)\n","      x = self.ups[idx+1](cat_path)\n","      print(cat_path.shape)\n","\n","    return self.final_conv(x)\n","\n","def test ():\n","  x = torch.randn((3, 1, 160 , 160))  # batch size, inputchannel,\n","  model = UNET(in_channels = 1, out_channels = 1)\n","  preds = model(x)\n","  print(preds.shape, x.shape)\n","  assert preds.shape == x.shape\n","\n","if __name__ == \"__main__\" :\n","  test()\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNCzWSEYqve8","executionInfo":{"status":"ok","timestamp":1746942224834,"user_tz":360,"elapsed":3578,"user":{"displayName":"Alan Ulises Díaz Arenas","userId":"02926404634191896650"}},"outputId":"40de19df-e1e6-425a-8f84-93f904b0d903"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 1024, 20, 20])\n","torch.Size([3, 512, 40, 40])\n","torch.Size([3, 256, 80, 80])\n","torch.Size([3, 128, 160, 160])\n","torch.Size([3, 1, 160, 160]) torch.Size([3, 1, 160, 160])\n"]}]}]}